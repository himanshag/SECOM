{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8CoiNMU1IQ8"
   },
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VNPgCs7b1Jso"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import plotly as py\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za0s4Egl1QU5"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RlMVRmdS1R0l"
   },
   "outputs": [],
   "source": [
    "# Function to remove missing values above a given threshold\n",
    "def missing_remove(dataframe, threshold):\n",
    "    columns = dataframe.columns[(dataframe.isna().sum()/dataframe.shape[1])>threshold].tolist()\n",
    "    print(f\"# Features deleted with more than {threshold} % missing values\", len(columns))\n",
    "    return dataframe.drop(columns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i62Cd7qc1LeI"
   },
   "outputs": [],
   "source": [
    "# Function to remove features with unique values\n",
    "def unique_remove(dataframe):\n",
    "    unique_features = []\n",
    "    for col in dataframe.columns:\n",
    "        if(dataframe[col].unique().size == 2):\n",
    "            if(len(unique_features) == 0):\n",
    "                unique_features =  dataframe[col]\n",
    "            else:\n",
    "                 unique_features = pd.concat([unique_features, dataframe[col]], axis=1)\n",
    "            dataframe.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "j_OUWkYC1WQD"
   },
   "outputs": [],
   "source": [
    "# Function to remove outlier\n",
    "def outlier_detection_zcore(dataframe):\n",
    "    data_mean, data_std  = dataframe.mean(), dataframe.std()\n",
    "    data_z_scores = ((dataframe - data_mean) / data_std).abs()\n",
    "    m = data_z_scores > 3\n",
    "    dataframe = dataframe.mask(m,inplace=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYimj7lt1efy"
   },
   "source": [
    "## Importing and basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LbJIxqWC1hBn"
   },
   "outputs": [],
   "source": [
    "# Importing data from internet in runtime\n",
    "data_url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vLONGBRz1iz7"
   },
   "outputs": [],
   "source": [
    "# Assigning data to a pandas dataframe\n",
    "secom_data = pd.read_csv(data_url,sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "mJ-CpITl1lJG",
    "outputId": "b3a93674-6003-41b9-c2b3-ad8f5c16698c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_581</th>\n",
       "      <th>Feature_582</th>\n",
       "      <th>Feature_583</th>\n",
       "      <th>Feature_584</th>\n",
       "      <th>Feature_585</th>\n",
       "      <th>Feature_586</th>\n",
       "      <th>Feature_587</th>\n",
       "      <th>Feature_588</th>\n",
       "      <th>Feature_589</th>\n",
       "      <th>Feature_590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0    3030.93    2564.00  2187.7333  1411.1265     1.3602      100.0   \n",
       "1    3095.78    2465.14  2230.4222  1463.6606     0.8294      100.0   \n",
       "2    2932.61    2559.94  2186.4111  1698.0172     1.5102      100.0   \n",
       "3    2988.72    2479.90  2199.0333   909.7926     1.3204      100.0   \n",
       "4    3032.24    2502.87  2233.3667  1326.5200     1.5334      100.0   \n",
       "\n",
       "   Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_581  Feature_582  \\\n",
       "0    97.6133     0.1242     1.5005      0.0162  ...          NaN          NaN   \n",
       "1   102.3433     0.1247     1.4966     -0.0005  ...       0.0060     208.2045   \n",
       "2    95.4878     0.1241     1.4436      0.0041  ...       0.0148      82.8602   \n",
       "3   104.2367     0.1217     1.4882     -0.0124  ...       0.0044      73.8432   \n",
       "4   100.3967     0.1235     1.5031     -0.0031  ...          NaN          NaN   \n",
       "\n",
       "   Feature_583  Feature_584  Feature_585  Feature_586  Feature_587  \\\n",
       "0       0.5005       0.0118       0.0035       2.3630          NaN   \n",
       "1       0.5019       0.0223       0.0055       4.4447       0.0096   \n",
       "2       0.4958       0.0157       0.0039       3.1745       0.0584   \n",
       "3       0.4990       0.0103       0.0025       2.0544       0.0202   \n",
       "4       0.4800       0.4766       0.1045      99.3032       0.0202   \n",
       "\n",
       "   Feature_588  Feature_589  Feature_590  \n",
       "0          NaN          NaN          NaN  \n",
       "1       0.0201       0.0060     208.2045  \n",
       "2       0.0484       0.0148      82.8602  \n",
       "3       0.0149       0.0044      73.8432  \n",
       "4       0.0149       0.0044      73.8432  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the columns \n",
    "secom_data.columns = [\"Feature_\"+str(column+1) for column in range(len(secom_data.columns))]\n",
    "secom_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1m82GHOT1msU"
   },
   "outputs": [],
   "source": [
    "# Importing target data from internet in runtime\n",
    "label_url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MXNuzPJe1sNk"
   },
   "outputs": [],
   "source": [
    "# Assigning target data to a pandas dataframe\n",
    "secom_labels = pd.read_csv(label_url, sep = \" \",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RqtL5guL1tz7"
   },
   "outputs": [],
   "source": [
    "# Renaming the columns \n",
    "secom_labels.columns = [\"Classification\",\"Timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "84Dl-Fay1vz3"
   },
   "outputs": [],
   "source": [
    "# Changing datatype for consitency\n",
    "secom_labels['Timestamp'] = pd.to_datetime(secom_labels['Timestamp'],errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qSmgspyk1xcL"
   },
   "outputs": [],
   "source": [
    "# Merging the data\n",
    "data= pd.concat([secom_labels,secom_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "foQ0Zplo1yxq"
   },
   "outputs": [],
   "source": [
    "# Dropping the timestamp column as it provides no insights\n",
    "data.drop(columns=\"Timestamp\", errors='raise',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wSd7j_0210WF"
   },
   "outputs": [],
   "source": [
    "target = data[['Classification']]\n",
    "data.drop(['Classification'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcnUqd02122m"
   },
   "source": [
    "## Spliting the data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UfkKHvKQ14hm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target, test_size=0.25, random_state=42, stratify=target)\n",
    "# We use the startify parameter as the data is imbalanced on the basis of pass and fail and this will ensure the same \n",
    "#is retained when we split - Random state will help us create a reproducible data - Test size is the split ration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VngQ8qmq18L2"
   },
   "source": [
    "## Re-labeling the Target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Zita67WD18oW"
   },
   "outputs": [],
   "source": [
    "# Relabeling target variables 1 is pass and 0 is fail\n",
    "y_train = y_train.replace(to_replace=[-1, 1], value=[1, 0])\n",
    "y_test = y_test.replace(to_replace=[-1, 1], value=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Qqf5h04o2BV3"
   },
   "outputs": [],
   "source": [
    "# # Scaling the data\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "# X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ktw4-If-2JVo"
   },
   "source": [
    "## Removing columns with more that 50% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sealjvqy16tt",
    "outputId": "164500ed-df5c-4369-d435-962dbc837897"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 590)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3sSkLKz2MQv",
    "outputId": "cdb55c6a-73da-4471-bd1c-24115ab55427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Features deleted with more than 0.5 % missing values 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1175, 558)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_remove(X_train, 0.5)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ch_hcYMU2OJQ"
   },
   "outputs": [],
   "source": [
    "## Removing Columns with non unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nKubTxv2Qio",
    "outputId": "6087e77d-932c-40a9-fa07-26da8eb42ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 442)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_remove(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODaHzF7B2SS0",
    "outputId": "4ad0e77b-18b1-4436-927c-bb2000ec5948"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 442)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From test set deleting columns that are removed in training set\n",
    "X_test = X_test[np.array(X_train.columns)]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def Outlier(X) :\n",
    "       \n",
    "        z_train= pd.DataFrame(stats.zscore(X,nan_policy='omit'))\n",
    "        z_train\n",
    "       \n",
    "        print('Number of Outliers : ',sum(z_train.apply(lambda x: sum(x.apply(lambda x: 1 if abs(x)>3 else 0)))))\n",
    "\n",
    "        is_outlier = abs(z_train)>3\n",
    "        is_outlier.columns = X.columns\n",
    "        is_outlier.index = X.index\n",
    "        return(X.mask(is_outlier, np.nan))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy import stats\n",
    "X_train = Outlier(X_train)\n",
    "X_test = Outlier(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\public\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:700: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# impute na values using MICE\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "MICE_imputer = IterativeImputer(random_state=100)\n",
    "X_train_MICE = X_train.copy(deep=True)\n",
    "X_train_MICE.iloc[:,:] = pd.DataFrame(MICE_imputer.fit_transform(X_train))\n",
    "X_train = X_train_MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>Feature_11</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_577</th>\n",
       "      <th>Feature_578</th>\n",
       "      <th>Feature_583</th>\n",
       "      <th>Feature_584</th>\n",
       "      <th>Feature_585</th>\n",
       "      <th>Feature_586</th>\n",
       "      <th>Feature_587</th>\n",
       "      <th>Feature_588</th>\n",
       "      <th>Feature_589</th>\n",
       "      <th>Feature_590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3057.03</td>\n",
       "      <td>2468.41</td>\n",
       "      <td>2184.8778</td>\n",
       "      <td>960.8486</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>102.5333</td>\n",
       "      <td>0.1214</td>\n",
       "      <td>1.4549</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-0.0196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0653</td>\n",
       "      <td>15.0191</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.4798</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>62.1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>3012.09</td>\n",
       "      <td>2551.08</td>\n",
       "      <td>2216.7333</td>\n",
       "      <td>1748.0885</td>\n",
       "      <td>1.1127</td>\n",
       "      <td>97.5822</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5136</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4530</td>\n",
       "      <td>12.7241</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.4634</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>62.3602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3032.81</td>\n",
       "      <td>2534.74</td>\n",
       "      <td>2239.4223</td>\n",
       "      <td>1997.3782</td>\n",
       "      <td>1.5397</td>\n",
       "      <td>98.3356</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>1.4974</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5902</td>\n",
       "      <td>18.6118</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0137</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>35.5550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2987.72</td>\n",
       "      <td>2550.52</td>\n",
       "      <td>2180.7000</td>\n",
       "      <td>1159.3838</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>98.9367</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>1.4207</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0056</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5141</td>\n",
       "      <td>11.3379</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1.9562</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>474.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>3001.90</td>\n",
       "      <td>2465.51</td>\n",
       "      <td>2223.0444</td>\n",
       "      <td>1194.5986</td>\n",
       "      <td>1.2016</td>\n",
       "      <td>112.5811</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>1.4201</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>...</td>\n",
       "      <td>83.9190</td>\n",
       "      <td>67.3679</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>1.6862</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>42.5048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>3185.69</td>\n",
       "      <td>2537.68</td>\n",
       "      <td>2173.2778</td>\n",
       "      <td>1116.2950</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>103.8200</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>1.4653</td>\n",
       "      <td>-0.0204</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0597</td>\n",
       "      <td>13.1807</td>\n",
       "      <td>0.5055</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>2.0588</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>41.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2988.92</td>\n",
       "      <td>2460.91</td>\n",
       "      <td>2178.0778</td>\n",
       "      <td>941.9524</td>\n",
       "      <td>0.8039</td>\n",
       "      <td>104.0167</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>1.5829</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>-0.0324</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2816</td>\n",
       "      <td>10.4728</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>2.9645</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>46.4165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>2975.74</td>\n",
       "      <td>2517.35</td>\n",
       "      <td>2162.5556</td>\n",
       "      <td>1041.0369</td>\n",
       "      <td>1.4305</td>\n",
       "      <td>100.4111</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>1.4968</td>\n",
       "      <td>-0.0201</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0949</td>\n",
       "      <td>16.9589</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.3077</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>23.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2928.16</td>\n",
       "      <td>2523.21</td>\n",
       "      <td>2210.6111</td>\n",
       "      <td>1184.6481</td>\n",
       "      <td>1.2577</td>\n",
       "      <td>102.9356</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>1.4453</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8020</td>\n",
       "      <td>7.1763</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>3.1882</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>293.2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2929.84</td>\n",
       "      <td>2504.50</td>\n",
       "      <td>2183.3111</td>\n",
       "      <td>1588.5090</td>\n",
       "      <td>1.6269</td>\n",
       "      <td>102.8467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.5545</td>\n",
       "      <td>-0.0370</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0907</td>\n",
       "      <td>6.5821</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>3.0151</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>63.0838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1175 rows × 442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_7  \\\n",
       "160     3057.03    2468.41  2184.8778   960.8486     1.0160   102.5333   \n",
       "814     3012.09    2551.08  2216.7333  1748.0885     1.1127    97.5822   \n",
       "124     3032.81    2534.74  2239.4223  1997.3782     1.5397    98.3356   \n",
       "501     2987.72    2550.52  2180.7000  1159.3838     1.0177    98.9367   \n",
       "1362    3001.90    2465.51  2223.0444  1194.5986     1.2016   112.5811   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1250    3185.69    2537.68  2173.2778  1116.2950     0.8525   103.8200   \n",
       "365     2988.92    2460.91  2178.0778   941.9524     0.8039   104.0167   \n",
       "1420    2975.74    2517.35  2162.5556  1041.0369     1.4305   100.4111   \n",
       "113     2928.16    2523.21  2210.6111  1184.6481     1.2577   102.9356   \n",
       "470     2929.84    2504.50  2183.3111  1588.5090     1.6269   102.8467   \n",
       "\n",
       "      Feature_8  Feature_9  Feature_10  Feature_11  ...  Feature_577  \\\n",
       "160      0.1214     1.4549     -0.0125     -0.0196  ...       1.0653   \n",
       "814      0.1242     1.5136     -0.0090      0.0129  ...       2.4530   \n",
       "124      0.1229     1.4974     -0.0046     -0.0002  ...       1.5902   \n",
       "501      0.1222     1.4207      0.0016     -0.0056  ...       1.5141   \n",
       "1362     0.1229     1.4201     -0.0182      0.0055  ...      83.9190   \n",
       "...         ...        ...         ...         ...  ...          ...   \n",
       "1250     0.1237     1.4653     -0.0204      0.0038  ...       1.0597   \n",
       "365      0.1229     1.5829     -0.0278     -0.0324  ...       1.2816   \n",
       "1420     0.1238     1.4968     -0.0201     -0.0060  ...       1.0949   \n",
       "113      0.1201     1.4453     -0.0126      0.0152  ...       1.8020   \n",
       "470      0.1248     1.5545     -0.0370     -0.0001  ...       2.0907   \n",
       "\n",
       "      Feature_578  Feature_583  Feature_584  Feature_585  Feature_586  \\\n",
       "160       15.0191       0.5067       0.0126       0.0034       2.4798   \n",
       "814       12.7241       0.4994       0.0073       0.0020       1.4634   \n",
       "124       18.6118       0.4950       0.0149       0.0041       3.0137   \n",
       "501       11.3379       0.5042       0.0099       0.0030       1.9562   \n",
       "1362      67.3679       0.5026       0.0085       0.0026       1.6862   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1250      13.1807       0.5055       0.0104       0.0028       2.0588   \n",
       "365       10.4728       0.4976       0.0148       0.0032       2.9645   \n",
       "1420      16.9589       0.4994       0.0115       0.0033       2.3077   \n",
       "113        7.1763       0.5016       0.0160       0.0035       3.1882   \n",
       "470        6.5821       0.4985       0.0150       0.0045       3.0151   \n",
       "\n",
       "      Feature_587  Feature_588  Feature_589  Feature_590  \n",
       "160        0.0195       0.0121       0.0048      62.1248  \n",
       "814        0.0111       0.0069       0.0021      62.3602  \n",
       "124        0.0241       0.0086       0.0027      35.5550  \n",
       "501        0.0048       0.0226       0.0079     474.0812  \n",
       "1362       0.0182       0.0077       0.0025      42.5048  \n",
       "...           ...          ...          ...          ...  \n",
       "1250       0.0230       0.0095       0.0028      41.2178  \n",
       "365        0.0291       0.0135       0.0045      46.4165  \n",
       "1420       0.0299       0.0071       0.0020      23.6431  \n",
       "113        0.0049       0.0144       0.0047     293.2614  \n",
       "470        0.0193       0.0122       0.0040      63.0838  \n",
       "\n",
       "[1175 rows x 442 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy: TRAINING 0.9336170212765957\n"
     ]
    }
   ],
   "source": [
    "clfscore = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "clfscore.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print ('RF accuracy: TRAINING', clfscore.score(X_train,y_train.values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BORUTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta function\n",
    "\n",
    "def BorutaFeatureSelection (X, y) :\n",
    "    feature_names = np.array(X.columns)\n",
    "\n",
    "    model = model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    feature_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=100, max_iter=100)\n",
    "\n",
    "    feature_selector.fit(X.to_numpy(),y)\n",
    "\n",
    "    feature_selector.support_\n",
    "\n",
    "    feature_selector.ranking_\n",
    "\n",
    "    feature_ranks = list(zip(feature_names, \n",
    "                             feature_selector.ranking_, \n",
    "                             feature_selector.support_))\n",
    "\n",
    "    for feat in feature_ranks:\n",
    "        print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features = list()\n",
    "    indexes = np.where(feature_selector.ranking_ <= 1)\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features.append(feature_names[x])\n",
    "    print(final_features)\n",
    "    \n",
    "    return pd.DataFrame(X.filter(final_features)) , final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t442\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t442\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t442\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t442\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t442\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t442\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t442\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t20\n",
      "Rejected: \t422\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t17\n",
      "Rejected: \t422\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t17\n",
      "Rejected: \t422\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t17\n",
      "Rejected: \t422\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t13\n",
      "Rejected: \t424\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t13\n",
      "Rejected: \t424\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t13\n",
      "Rejected: \t424\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t13\n",
      "Rejected: \t424\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t12\n",
      "Rejected: \t424\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t12\n",
      "Rejected: \t424\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t12\n",
      "Rejected: \t424\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t11\n",
      "Rejected: \t424\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t11\n",
      "Rejected: \t424\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t11\n",
      "Rejected: \t424\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t9\n",
      "Rejected: \t424\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t8\n",
      "Rejected: \t424\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t8\n",
      "Rejected: \t424\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t6\n",
      "Rejected: \t424\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t6\n",
      "Rejected: \t424\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t6\n",
      "Rejected: \t424\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t6\n",
      "Rejected: \t424\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t6\n",
      "Rejected: \t424\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t6\n",
      "Rejected: \t424\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t5\n",
      "Rejected: \t424\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t425\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t425\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t15\n",
      "Tentative: \t2\n",
      "Rejected: \t425\n",
      "Feature: Feature_1                      Rank: 27,  Keep: False\n",
      "Feature: Feature_2                      Rank: 156,  Keep: False\n",
      "Feature: Feature_3                      Rank: 244,  Keep: False\n",
      "Feature: Feature_4                      Rank: 390,  Keep: False\n",
      "Feature: Feature_5                      Rank: 284,  Keep: False\n",
      "Feature: Feature_7                      Rank: 253,  Keep: False\n",
      "Feature: Feature_8                      Rank: 195,  Keep: False\n",
      "Feature: Feature_9                      Rank: 56,  Keep: False\n",
      "Feature: Feature_10                     Rank: 116,  Keep: False\n",
      "Feature: Feature_11                     Rank: 342,  Keep: False\n",
      "Feature: Feature_12                     Rank: 260,  Keep: False\n",
      "Feature: Feature_13                     Rank: 249,  Keep: False\n",
      "Feature: Feature_15                     Rank: 21,  Keep: False\n",
      "Feature: Feature_16                     Rank: 61,  Keep: False\n",
      "Feature: Feature_17                     Rank: 159,  Keep: False\n",
      "Feature: Feature_18                     Rank: 110,  Keep: False\n",
      "Feature: Feature_19                     Rank: 293,  Keep: False\n",
      "Feature: Feature_20                     Rank: 123,  Keep: False\n",
      "Feature: Feature_21                     Rank: 289,  Keep: False\n",
      "Feature: Feature_22                     Rank: 1,  Keep: True\n",
      "Feature: Feature_23                     Rank: 58,  Keep: False\n",
      "Feature: Feature_24                     Rank: 301,  Keep: False\n",
      "Feature: Feature_25                     Rank: 218,  Keep: False\n",
      "Feature: Feature_26                     Rank: 43,  Keep: False\n",
      "Feature: Feature_27                     Rank: 147,  Keep: False\n",
      "Feature: Feature_28                     Rank: 232,  Keep: False\n",
      "Feature: Feature_29                     Rank: 9,  Keep: False\n",
      "Feature: Feature_30                     Rank: 254,  Keep: False\n",
      "Feature: Feature_31                     Rank: 324,  Keep: False\n",
      "Feature: Feature_32                     Rank: 1,  Keep: True\n",
      "Feature: Feature_33                     Rank: 352,  Keep: False\n",
      "Feature: Feature_34                     Rank: 1,  Keep: True\n",
      "Feature: Feature_35                     Rank: 165,  Keep: False\n",
      "Feature: Feature_36                     Rank: 148,  Keep: False\n",
      "Feature: Feature_37                     Rank: 185,  Keep: False\n",
      "Feature: Feature_38                     Rank: 47,  Keep: False\n",
      "Feature: Feature_39                     Rank: 117,  Keep: False\n",
      "Feature: Feature_40                     Rank: 99,  Keep: False\n",
      "Feature: Feature_41                     Rank: 96,  Keep: False\n",
      "Feature: Feature_42                     Rank: 227,  Keep: False\n",
      "Feature: Feature_44                     Rank: 114,  Keep: False\n",
      "Feature: Feature_45                     Rank: 309,  Keep: False\n",
      "Feature: Feature_46                     Rank: 179,  Keep: False\n",
      "Feature: Feature_47                     Rank: 348,  Keep: False\n",
      "Feature: Feature_48                     Rank: 194,  Keep: False\n",
      "Feature: Feature_49                     Rank: 107,  Keep: False\n",
      "Feature: Feature_51                     Rank: 250,  Keep: False\n",
      "Feature: Feature_52                     Rank: 145,  Keep: False\n",
      "Feature: Feature_54                     Rank: 262,  Keep: False\n",
      "Feature: Feature_55                     Rank: 305,  Keep: False\n",
      "Feature: Feature_56                     Rank: 90,  Keep: False\n",
      "Feature: Feature_57                     Rank: 70,  Keep: False\n",
      "Feature: Feature_58                     Rank: 206,  Keep: False\n",
      "Feature: Feature_59                     Rank: 61,  Keep: False\n",
      "Feature: Feature_60                     Rank: 1,  Keep: True\n",
      "Feature: Feature_61                     Rank: 202,  Keep: False\n",
      "Feature: Feature_62                     Rank: 146,  Keep: False\n",
      "Feature: Feature_63                     Rank: 108,  Keep: False\n",
      "Feature: Feature_64                     Rank: 17,  Keep: False\n",
      "Feature: Feature_65                     Rank: 1,  Keep: True\n",
      "Feature: Feature_66                     Rank: 1,  Keep: True\n",
      "Feature: Feature_67                     Rank: 127,  Keep: False\n",
      "Feature: Feature_68                     Rank: 115,  Keep: False\n",
      "Feature: Feature_69                     Rank: 104,  Keep: False\n",
      "Feature: Feature_71                     Rank: 152,  Keep: False\n",
      "Feature: Feature_72                     Rank: 286,  Keep: False\n",
      "Feature: Feature_75                     Rank: 426,  Keep: False\n",
      "Feature: Feature_76                     Rank: 83,  Keep: False\n",
      "Feature: Feature_77                     Rank: 81,  Keep: False\n",
      "Feature: Feature_78                     Rank: 279,  Keep: False\n",
      "Feature: Feature_79                     Rank: 8,  Keep: False\n",
      "Feature: Feature_80                     Rank: 67,  Keep: False\n",
      "Feature: Feature_81                     Rank: 235,  Keep: False\n",
      "Feature: Feature_82                     Rank: 12,  Keep: False\n",
      "Feature: Feature_83                     Rank: 315,  Keep: False\n",
      "Feature: Feature_84                     Rank: 301,  Keep: False\n",
      "Feature: Feature_85                     Rank: 386,  Keep: False\n",
      "Feature: Feature_87                     Rank: 110,  Keep: False\n",
      "Feature: Feature_88                     Rank: 405,  Keep: False\n",
      "Feature: Feature_89                     Rank: 284,  Keep: False\n",
      "Feature: Feature_90                     Rank: 157,  Keep: False\n",
      "Feature: Feature_91                     Rank: 67,  Keep: False\n",
      "Feature: Feature_92                     Rank: 33,  Keep: False\n",
      "Feature: Feature_93                     Rank: 270,  Keep: False\n",
      "Feature: Feature_94                     Rank: 299,  Keep: False\n",
      "Feature: Feature_95                     Rank: 414,  Keep: False\n",
      "Feature: Feature_96                     Rank: 90,  Keep: False\n",
      "Feature: Feature_97                     Rank: 337,  Keep: False\n",
      "Feature: Feature_99                     Rank: 328,  Keep: False\n",
      "Feature: Feature_100                    Rank: 272,  Keep: False\n",
      "Feature: Feature_101                    Rank: 78,  Keep: False\n",
      "Feature: Feature_102                    Rank: 415,  Keep: False\n",
      "Feature: Feature_103                    Rank: 14,  Keep: False\n",
      "Feature: Feature_104                    Rank: 1,  Keep: True\n",
      "Feature: Feature_105                    Rank: 278,  Keep: False\n",
      "Feature: Feature_106                    Rank: 342,  Keep: False\n",
      "Feature: Feature_107                    Rank: 371,  Keep: False\n",
      "Feature: Feature_108                    Rank: 177,  Keep: False\n",
      "Feature: Feature_109                    Rank: 212,  Keep: False\n",
      "Feature: Feature_114                    Rank: 174,  Keep: False\n",
      "Feature: Feature_115                    Rank: 418,  Keep: False\n",
      "Feature: Feature_116                    Rank: 120,  Keep: False\n",
      "Feature: Feature_117                    Rank: 176,  Keep: False\n",
      "Feature: Feature_118                    Rank: 102,  Keep: False\n",
      "Feature: Feature_119                    Rank: 257,  Keep: False\n",
      "Feature: Feature_120                    Rank: 369,  Keep: False\n",
      "Feature: Feature_121                    Rank: 190,  Keep: False\n",
      "Feature: Feature_122                    Rank: 1,  Keep: True\n",
      "Feature: Feature_123                    Rank: 36,  Keep: False\n",
      "Feature: Feature_124                    Rank: 32,  Keep: False\n",
      "Feature: Feature_125                    Rank: 6,  Keep: False\n",
      "Feature: Feature_126                    Rank: 3,  Keep: False\n",
      "Feature: Feature_127                    Rank: 25,  Keep: False\n",
      "Feature: Feature_128                    Rank: 29,  Keep: False\n",
      "Feature: Feature_129                    Rank: 238,  Keep: False\n",
      "Feature: Feature_130                    Rank: 4,  Keep: False\n",
      "Feature: Feature_131                    Rank: 1,  Keep: True\n",
      "Feature: Feature_132                    Rank: 174,  Keep: False\n",
      "Feature: Feature_133                    Rank: 57,  Keep: False\n",
      "Feature: Feature_134                    Rank: 93,  Keep: False\n",
      "Feature: Feature_135                    Rank: 358,  Keep: False\n",
      "Feature: Feature_136                    Rank: 211,  Keep: False\n",
      "Feature: Feature_137                    Rank: 342,  Keep: False\n",
      "Feature: Feature_138                    Rank: 221,  Keep: False\n",
      "Feature: Feature_139                    Rank: 215,  Keep: False\n",
      "Feature: Feature_140                    Rank: 210,  Keep: False\n",
      "Feature: Feature_141                    Rank: 246,  Keep: False\n",
      "Feature: Feature_143                    Rank: 301,  Keep: False\n",
      "Feature: Feature_144                    Rank: 183,  Keep: False\n",
      "Feature: Feature_145                    Rank: 134,  Keep: False\n",
      "Feature: Feature_146                    Rank: 169,  Keep: False\n",
      "Feature: Feature_147                    Rank: 55,  Keep: False\n",
      "Feature: Feature_148                    Rank: 46,  Keep: False\n",
      "Feature: Feature_149                    Rank: 378,  Keep: False\n",
      "Feature: Feature_151                    Rank: 312,  Keep: False\n",
      "Feature: Feature_152                    Rank: 332,  Keep: False\n",
      "Feature: Feature_153                    Rank: 12,  Keep: False\n",
      "Feature: Feature_154                    Rank: 88,  Keep: False\n",
      "Feature: Feature_155                    Rank: 350,  Keep: False\n",
      "Feature: Feature_156                    Rank: 150,  Keep: False\n",
      "Feature: Feature_157                    Rank: 94,  Keep: False\n",
      "Feature: Feature_160                    Rank: 126,  Keep: False\n",
      "Feature: Feature_161                    Rank: 72,  Keep: False\n",
      "Feature: Feature_162                    Rank: 191,  Keep: False\n",
      "Feature: Feature_163                    Rank: 272,  Keep: False\n",
      "Feature: Feature_164                    Rank: 51,  Keep: False\n",
      "Feature: Feature_165                    Rank: 334,  Keep: False\n",
      "Feature: Feature_166                    Rank: 411,  Keep: False\n",
      "Feature: Feature_167                    Rank: 412,  Keep: False\n",
      "Feature: Feature_168                    Rank: 395,  Keep: False\n",
      "Feature: Feature_169                    Rank: 357,  Keep: False\n",
      "Feature: Feature_170                    Rank: 383,  Keep: False\n",
      "Feature: Feature_171                    Rank: 167,  Keep: False\n",
      "Feature: Feature_172                    Rank: 243,  Keep: False\n",
      "Feature: Feature_173                    Rank: 159,  Keep: False\n",
      "Feature: Feature_174                    Rank: 188,  Keep: False\n",
      "Feature: Feature_175                    Rank: 98,  Keep: False\n",
      "Feature: Feature_176                    Rank: 5,  Keep: False\n",
      "Feature: Feature_177                    Rank: 296,  Keep: False\n",
      "Feature: Feature_178                    Rank: 217,  Keep: False\n",
      "Feature: Feature_181                    Rank: 16,  Keep: False\n",
      "Feature: Feature_182                    Rank: 86,  Keep: False\n",
      "Feature: Feature_183                    Rank: 41,  Keep: False\n",
      "Feature: Feature_184                    Rank: 6,  Keep: False\n",
      "Feature: Feature_185                    Rank: 242,  Keep: False\n",
      "Feature: Feature_186                    Rank: 319,  Keep: False\n",
      "Feature: Feature_188                    Rank: 112,  Keep: False\n",
      "Feature: Feature_189                    Rank: 58,  Keep: False\n",
      "Feature: Feature_196                    Rank: 172,  Keep: False\n",
      "Feature: Feature_197                    Rank: 372,  Keep: False\n",
      "Feature: Feature_198                    Rank: 137,  Keep: False\n",
      "Feature: Feature_199                    Rank: 367,  Keep: False\n",
      "Feature: Feature_200                    Rank: 311,  Keep: False\n",
      "Feature: Feature_201                    Rank: 23,  Keep: False\n",
      "Feature: Feature_202                    Rank: 248,  Keep: False\n",
      "Feature: Feature_203                    Rank: 74,  Keep: False\n",
      "Feature: Feature_204                    Rank: 125,  Keep: False\n",
      "Feature: Feature_205                    Rank: 268,  Keep: False\n",
      "Feature: Feature_206                    Rank: 2,  Keep: False\n",
      "Feature: Feature_207                    Rank: 423,  Keep: False\n",
      "Feature: Feature_208                    Rank: 174,  Keep: False\n",
      "Feature: Feature_209                    Rank: 265,  Keep: False\n",
      "Feature: Feature_210                    Rank: 423,  Keep: False\n",
      "Feature: Feature_211                    Rank: 77,  Keep: False\n",
      "Feature: Feature_212                    Rank: 280,  Keep: False\n",
      "Feature: Feature_213                    Rank: 364,  Keep: False\n",
      "Feature: Feature_214                    Rank: 1,  Keep: True\n",
      "Feature: Feature_215                    Rank: 349,  Keep: False\n",
      "Feature: Feature_216                    Rank: 229,  Keep: False\n",
      "Feature: Feature_217                    Rank: 196,  Keep: False\n",
      "Feature: Feature_218                    Rank: 167,  Keep: False\n",
      "Feature: Feature_219                    Rank: 212,  Keep: False\n",
      "Feature: Feature_220                    Rank: 390,  Keep: False\n",
      "Feature: Feature_222                    Rank: 388,  Keep: False\n",
      "Feature: Feature_223                    Rank: 361,  Keep: False\n",
      "Feature: Feature_224                    Rank: 353,  Keep: False\n",
      "Feature: Feature_225                    Rank: 345,  Keep: False\n",
      "Feature: Feature_226                    Rank: 164,  Keep: False\n",
      "Feature: Feature_228                    Rank: 37,  Keep: False\n",
      "Feature: Feature_229                    Rank: 180,  Keep: False\n",
      "Feature: Feature_239                    Rank: 393,  Keep: False\n",
      "Feature: Feature_240                    Rank: 284,  Keep: False\n",
      "Feature: Feature_249                    Rank: 257,  Keep: False\n",
      "Feature: Feature_250                    Rank: 420,  Keep: False\n",
      "Feature: Feature_251                    Rank: 122,  Keep: False\n",
      "Feature: Feature_252                    Rank: 309,  Keep: False\n",
      "Feature: Feature_253                    Rank: 199,  Keep: False\n",
      "Feature: Feature_254                    Rank: 241,  Keep: False\n",
      "Feature: Feature_255                    Rank: 232,  Keep: False\n",
      "Feature: Feature_256                    Rank: 327,  Keep: False\n",
      "Feature: Feature_268                    Rank: 119,  Keep: False\n",
      "Feature: Feature_269                    Rank: 182,  Keep: False\n",
      "Feature: Feature_270                    Rank: 247,  Keep: False\n",
      "Feature: Feature_271                    Rank: 50,  Keep: False\n",
      "Feature: Feature_272                    Rank: 215,  Keep: False\n",
      "Feature: Feature_273                    Rank: 309,  Keep: False\n",
      "Feature: Feature_274                    Rank: 294,  Keep: False\n",
      "Feature: Feature_275                    Rank: 266,  Keep: False\n",
      "Feature: Feature_276                    Rank: 400,  Keep: False\n",
      "Feature: Feature_278                    Rank: 292,  Keep: False\n",
      "Feature: Feature_279                    Rank: 412,  Keep: False\n",
      "Feature: Feature_280                    Rank: 89,  Keep: False\n",
      "Feature: Feature_281                    Rank: 75,  Keep: False\n",
      "Feature: Feature_282                    Rank: 18,  Keep: False\n",
      "Feature: Feature_283                    Rank: 48,  Keep: False\n",
      "Feature: Feature_284                    Rank: 307,  Keep: False\n",
      "Feature: Feature_286                    Rank: 274,  Keep: False\n",
      "Feature: Feature_287                    Rank: 188,  Keep: False\n",
      "Feature: Feature_288                    Rank: 22,  Keep: False\n",
      "Feature: Feature_289                    Rank: 132,  Keep: False\n",
      "Feature: Feature_290                    Rank: 378,  Keep: False\n",
      "Feature: Feature_291                    Rank: 69,  Keep: False\n",
      "Feature: Feature_292                    Rank: 171,  Keep: False\n",
      "Feature: Feature_295                    Rank: 155,  Keep: False\n",
      "Feature: Feature_296                    Rank: 81,  Keep: False\n",
      "Feature: Feature_297                    Rank: 157,  Keep: False\n",
      "Feature: Feature_298                    Rank: 282,  Keep: False\n",
      "Feature: Feature_299                    Rank: 23,  Keep: False\n",
      "Feature: Feature_300                    Rank: 230,  Keep: False\n",
      "Feature: Feature_301                    Rank: 402,  Keep: False\n",
      "Feature: Feature_302                    Rank: 389,  Keep: False\n",
      "Feature: Feature_303                    Rank: 381,  Keep: False\n",
      "Feature: Feature_304                    Rank: 161,  Keep: False\n",
      "Feature: Feature_305                    Rank: 198,  Keep: False\n",
      "Feature: Feature_306                    Rank: 215,  Keep: False\n",
      "Feature: Feature_307                    Rank: 226,  Keep: False\n",
      "Feature: Feature_308                    Rank: 100,  Keep: False\n",
      "Feature: Feature_309                    Rank: 203,  Keep: False\n",
      "Feature: Feature_310                    Rank: 52,  Keep: False\n",
      "Feature: Feature_311                    Rank: 14,  Keep: False\n",
      "Feature: Feature_312                    Rank: 275,  Keep: False\n",
      "Feature: Feature_313                    Rank: 263,  Keep: False\n",
      "Feature: Feature_317                    Rank: 20,  Keep: False\n",
      "Feature: Feature_318                    Rank: 25,  Keep: False\n",
      "Feature: Feature_319                    Rank: 227,  Keep: False\n",
      "Feature: Feature_320                    Rank: 1,  Keep: True\n",
      "Feature: Feature_321                    Rank: 236,  Keep: False\n",
      "Feature: Feature_322                    Rank: 324,  Keep: False\n",
      "Feature: Feature_324                    Rank: 64,  Keep: False\n",
      "Feature: Feature_325                    Rank: 94,  Keep: False\n",
      "Feature: Feature_332                    Rank: 86,  Keep: False\n",
      "Feature: Feature_333                    Rank: 399,  Keep: False\n",
      "Feature: Feature_334                    Rank: 37,  Keep: False\n",
      "Feature: Feature_335                    Rank: 366,  Keep: False\n",
      "Feature: Feature_336                    Rank: 244,  Keep: False\n",
      "Feature: Feature_337                    Rank: 28,  Keep: False\n",
      "Feature: Feature_338                    Rank: 407,  Keep: False\n",
      "Feature: Feature_339                    Rank: 184,  Keep: False\n",
      "Feature: Feature_340                    Rank: 317,  Keep: False\n",
      "Feature: Feature_341                    Rank: 346,  Keep: False\n",
      "Feature: Feature_342                    Rank: 2,  Keep: False\n",
      "Feature: Feature_343                    Rank: 426,  Keep: False\n",
      "Feature: Feature_344                    Rank: 150,  Keep: False\n",
      "Feature: Feature_345                    Rank: 138,  Keep: False\n",
      "Feature: Feature_348                    Rank: 426,  Keep: False\n",
      "Feature: Feature_349                    Rank: 31,  Keep: False\n",
      "Feature: Feature_350                    Rank: 316,  Keep: False\n",
      "Feature: Feature_351                    Rank: 386,  Keep: False\n",
      "Feature: Feature_352                    Rank: 1,  Keep: True\n",
      "Feature: Feature_353                    Rank: 239,  Keep: False\n",
      "Feature: Feature_354                    Rank: 251,  Keep: False\n",
      "Feature: Feature_355                    Rank: 192,  Keep: False\n",
      "Feature: Feature_356                    Rank: 153,  Keep: False\n",
      "Feature: Feature_357                    Rank: 330,  Keep: False\n",
      "Feature: Feature_358                    Rank: 406,  Keep: False\n",
      "Feature: Feature_360                    Rank: 376,  Keep: False\n",
      "Feature: Feature_361                    Rank: 369,  Keep: False\n",
      "Feature: Feature_362                    Rank: 397,  Keep: False\n",
      "Feature: Feature_363                    Rank: 401,  Keep: False\n",
      "Feature: Feature_364                    Rank: 251,  Keep: False\n",
      "Feature: Feature_366                    Rank: 75,  Keep: False\n",
      "Feature: Feature_367                    Rank: 280,  Keep: False\n",
      "Feature: Feature_368                    Rank: 408,  Keep: False\n",
      "Feature: Feature_369                    Rank: 326,  Keep: False\n",
      "Feature: Feature_377                    Rank: 408,  Keep: False\n",
      "Feature: Feature_378                    Rank: 97,  Keep: False\n",
      "Feature: Feature_387                    Rank: 313,  Keep: False\n",
      "Feature: Feature_388                    Rank: 419,  Keep: False\n",
      "Feature: Feature_389                    Rank: 109,  Keep: False\n",
      "Feature: Feature_390                    Rank: 417,  Keep: False\n",
      "Feature: Feature_391                    Rank: 118,  Keep: False\n",
      "Feature: Feature_392                    Rank: 223,  Keep: False\n",
      "Feature: Feature_393                    Rank: 335,  Keep: False\n",
      "Feature: Feature_394                    Rank: 301,  Keep: False\n",
      "Feature: Feature_406                    Rank: 39,  Keep: False\n",
      "Feature: Feature_407                    Rank: 127,  Keep: False\n",
      "Feature: Feature_408                    Rank: 384,  Keep: False\n",
      "Feature: Feature_409                    Rank: 142,  Keep: False\n",
      "Feature: Feature_410                    Rank: 360,  Keep: False\n",
      "Feature: Feature_411                    Rank: 224,  Keep: False\n",
      "Feature: Feature_412                    Rank: 208,  Keep: False\n",
      "Feature: Feature_413                    Rank: 161,  Keep: False\n",
      "Feature: Feature_414                    Rank: 206,  Keep: False\n",
      "Feature: Feature_416                    Rank: 396,  Keep: False\n",
      "Feature: Feature_417                    Rank: 100,  Keep: False\n",
      "Feature: Feature_418                    Rank: 45,  Keep: False\n",
      "Feature: Feature_419                    Rank: 382,  Keep: False\n",
      "Feature: Feature_420                    Rank: 404,  Keep: False\n",
      "Feature: Feature_421                    Rank: 49,  Keep: False\n",
      "Feature: Feature_422                    Rank: 328,  Keep: False\n",
      "Feature: Feature_424                    Rank: 35,  Keep: False\n",
      "Feature: Feature_425                    Rank: 294,  Keep: False\n",
      "Feature: Feature_426                    Rank: 19,  Keep: False\n",
      "Feature: Feature_427                    Rank: 80,  Keep: False\n",
      "Feature: Feature_428                    Rank: 398,  Keep: False\n",
      "Feature: Feature_429                    Rank: 63,  Keep: False\n",
      "Feature: Feature_430                    Rank: 166,  Keep: False\n",
      "Feature: Feature_431                    Rank: 135,  Keep: False\n",
      "Feature: Feature_432                    Rank: 54,  Keep: False\n",
      "Feature: Feature_433                    Rank: 163,  Keep: False\n",
      "Feature: Feature_434                    Rank: 105,  Keep: False\n",
      "Feature: Feature_435                    Rank: 234,  Keep: False\n",
      "Feature: Feature_436                    Rank: 131,  Keep: False\n",
      "Feature: Feature_437                    Rank: 298,  Keep: False\n",
      "Feature: Feature_438                    Rank: 330,  Keep: False\n",
      "Feature: Feature_439                    Rank: 322,  Keep: False\n",
      "Feature: Feature_440                    Rank: 255,  Keep: False\n",
      "Feature: Feature_441                    Rank: 350,  Keep: False\n",
      "Feature: Feature_442                    Rank: 181,  Keep: False\n",
      "Feature: Feature_443                    Rank: 272,  Keep: False\n",
      "Feature: Feature_444                    Rank: 143,  Keep: False\n",
      "Feature: Feature_445                    Rank: 197,  Keep: False\n",
      "Feature: Feature_446                    Rank: 141,  Keep: False\n",
      "Feature: Feature_447                    Rank: 11,  Keep: False\n",
      "Feature: Feature_448                    Rank: 333,  Keep: False\n",
      "Feature: Feature_449                    Rank: 364,  Keep: False\n",
      "Feature: Feature_453                    Rank: 40,  Keep: False\n",
      "Feature: Feature_454                    Rank: 133,  Keep: False\n",
      "Feature: Feature_455                    Rank: 64,  Keep: False\n",
      "Feature: Feature_456                    Rank: 10,  Keep: False\n",
      "Feature: Feature_457                    Rank: 203,  Keep: False\n",
      "Feature: Feature_458                    Rank: 385,  Keep: False\n",
      "Feature: Feature_460                    Rank: 121,  Keep: False\n",
      "Feature: Feature_461                    Rank: 34,  Keep: False\n",
      "Feature: Feature_468                    Rank: 154,  Keep: False\n",
      "Feature: Feature_469                    Rank: 61,  Keep: False\n",
      "Feature: Feature_470                    Rank: 41,  Keep: False\n",
      "Feature: Feature_471                    Rank: 255,  Keep: False\n",
      "Feature: Feature_472                    Rank: 221,  Keep: False\n",
      "Feature: Feature_473                    Rank: 266,  Keep: False\n",
      "Feature: Feature_474                    Rank: 193,  Keep: False\n",
      "Feature: Feature_475                    Rank: 296,  Keep: False\n",
      "Feature: Feature_476                    Rank: 113,  Keep: False\n",
      "Feature: Feature_477                    Rank: 205,  Keep: False\n",
      "Feature: Feature_478                    Rank: 1,  Keep: True\n",
      "Feature: Feature_479                    Rank: 421,  Keep: False\n",
      "Feature: Feature_480                    Rank: 123,  Keep: False\n",
      "Feature: Feature_481                    Rank: 148,  Keep: False\n",
      "Feature: Feature_483                    Rank: 410,  Keep: False\n",
      "Feature: Feature_484                    Rank: 380,  Keep: False\n",
      "Feature: Feature_485                    Rank: 291,  Keep: False\n",
      "Feature: Feature_486                    Rank: 200,  Keep: False\n",
      "Feature: Feature_487                    Rank: 144,  Keep: False\n",
      "Feature: Feature_488                    Rank: 290,  Keep: False\n",
      "Feature: Feature_489                    Rank: 30,  Keep: False\n",
      "Feature: Feature_490                    Rank: 106,  Keep: False\n",
      "Feature: Feature_491                    Rank: 129,  Keep: False\n",
      "Feature: Feature_492                    Rank: 269,  Keep: False\n",
      "Feature: Feature_494                    Rank: 367,  Keep: False\n",
      "Feature: Feature_495                    Rank: 358,  Keep: False\n",
      "Feature: Feature_496                    Rank: 342,  Keep: False\n",
      "Feature: Feature_497                    Rank: 403,  Keep: False\n",
      "Feature: Feature_498                    Rank: 219,  Keep: False\n",
      "Feature: Feature_500                    Rank: 84,  Keep: False\n",
      "Feature: Feature_501                    Rank: 313,  Keep: False\n",
      "Feature: Feature_511                    Rank: 1,  Keep: True\n",
      "Feature: Feature_512                    Rank: 129,  Keep: False\n",
      "Feature: Feature_521                    Rank: 361,  Keep: False\n",
      "Feature: Feature_522                    Rank: 421,  Keep: False\n",
      "Feature: Feature_523                    Rank: 92,  Keep: False\n",
      "Feature: Feature_524                    Rank: 261,  Keep: False\n",
      "Feature: Feature_525                    Rank: 138,  Keep: False\n",
      "Feature: Feature_526                    Rank: 354,  Keep: False\n",
      "Feature: Feature_527                    Rank: 374,  Keep: False\n",
      "Feature: Feature_528                    Rank: 374,  Keep: False\n",
      "Feature: Feature_540                    Rank: 136,  Keep: False\n",
      "Feature: Feature_541                    Rank: 239,  Keep: False\n",
      "Feature: Feature_542                    Rank: 275,  Keep: False\n",
      "Feature: Feature_543                    Rank: 337,  Keep: False\n",
      "Feature: Feature_544                    Rank: 347,  Keep: False\n",
      "Feature: Feature_545                    Rank: 416,  Keep: False\n",
      "Feature: Feature_546                    Rank: 355,  Keep: False\n",
      "Feature: Feature_547                    Rank: 277,  Keep: False\n",
      "Feature: Feature_548                    Rank: 72,  Keep: False\n",
      "Feature: Feature_549                    Rank: 394,  Keep: False\n",
      "Feature: Feature_550                    Rank: 78,  Keep: False\n",
      "Feature: Feature_551                    Rank: 306,  Keep: False\n",
      "Feature: Feature_552                    Rank: 232,  Keep: False\n",
      "Feature: Feature_553                    Rank: 187,  Keep: False\n",
      "Feature: Feature_554                    Rank: 259,  Keep: False\n",
      "Feature: Feature_555                    Rank: 377,  Keep: False\n",
      "Feature: Feature_556                    Rank: 287,  Keep: False\n",
      "Feature: Feature_557                    Rank: 339,  Keep: False\n",
      "Feature: Feature_558                    Rank: 177,  Keep: False\n",
      "Feature: Feature_559                    Rank: 304,  Keep: False\n",
      "Feature: Feature_560                    Rank: 185,  Keep: False\n",
      "Feature: Feature_561                    Rank: 201,  Keep: False\n",
      "Feature: Feature_562                    Rank: 102,  Keep: False\n",
      "Feature: Feature_563                    Rank: 52,  Keep: False\n",
      "Feature: Feature_564                    Rank: 67,  Keep: False\n",
      "Feature: Feature_565                    Rank: 342,  Keep: False\n",
      "Feature: Feature_566                    Rank: 321,  Keep: False\n",
      "Feature: Feature_567                    Rank: 392,  Keep: False\n",
      "Feature: Feature_568                    Rank: 363,  Keep: False\n",
      "Feature: Feature_569                    Rank: 355,  Keep: False\n",
      "Feature: Feature_570                    Rank: 208,  Keep: False\n",
      "Feature: Feature_571                    Rank: 320,  Keep: False\n",
      "Feature: Feature_572                    Rank: 170,  Keep: False\n",
      "Feature: Feature_573                    Rank: 373,  Keep: False\n",
      "Feature: Feature_574                    Rank: 43,  Keep: False\n",
      "Feature: Feature_575                    Rank: 219,  Keep: False\n",
      "Feature: Feature_576                    Rank: 140,  Keep: False\n",
      "Feature: Feature_577                    Rank: 337,  Keep: False\n",
      "Feature: Feature_578                    Rank: 1,  Keep: True\n",
      "Feature: Feature_583                    Rank: 263,  Keep: False\n",
      "Feature: Feature_584                    Rank: 237,  Keep: False\n",
      "Feature: Feature_585                    Rank: 225,  Keep: False\n",
      "Feature: Feature_586                    Rank: 287,  Keep: False\n",
      "Feature: Feature_587                    Rank: 317,  Keep: False\n",
      "Feature: Feature_588                    Rank: 71,  Keep: False\n",
      "Feature: Feature_589                    Rank: 86,  Keep: False\n",
      "Feature: Feature_590                    Rank: 322,  Keep: False\n",
      "['Feature_22', 'Feature_32', 'Feature_34', 'Feature_60', 'Feature_65', 'Feature_66', 'Feature_104', 'Feature_122', 'Feature_131', 'Feature_214', 'Feature_320', 'Feature_352', 'Feature_478', 'Feature_511', 'Feature_578']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "X_train , final_features = BorutaFeatureSelection(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_22</th>\n",
       "      <th>Feature_32</th>\n",
       "      <th>Feature_34</th>\n",
       "      <th>Feature_60</th>\n",
       "      <th>Feature_65</th>\n",
       "      <th>Feature_66</th>\n",
       "      <th>Feature_104</th>\n",
       "      <th>Feature_122</th>\n",
       "      <th>Feature_131</th>\n",
       "      <th>Feature_214</th>\n",
       "      <th>Feature_320</th>\n",
       "      <th>Feature_352</th>\n",
       "      <th>Feature_478</th>\n",
       "      <th>Feature_511</th>\n",
       "      <th>Feature_578</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-5645.25</td>\n",
       "      <td>3.3907</td>\n",
       "      <td>8.3754</td>\n",
       "      <td>14.645500</td>\n",
       "      <td>25.354500</td>\n",
       "      <td>34.515500</td>\n",
       "      <td>-0.0056</td>\n",
       "      <td>15.74</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.1156</td>\n",
       "      <td>10.0971</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>6.002000</td>\n",
       "      <td>97.7778</td>\n",
       "      <td>15.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>-6616.00</td>\n",
       "      <td>4.6484</td>\n",
       "      <td>8.6706</td>\n",
       "      <td>5.572236</td>\n",
       "      <td>15.453244</td>\n",
       "      <td>25.628517</td>\n",
       "      <td>-0.0106</td>\n",
       "      <td>15.86</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>8.6690</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>6.178896</td>\n",
       "      <td>50.8235</td>\n",
       "      <td>12.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-5653.75</td>\n",
       "      <td>3.3321</td>\n",
       "      <td>8.7947</td>\n",
       "      <td>29.191800</td>\n",
       "      <td>10.808200</td>\n",
       "      <td>17.468400</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>15.74</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>10.8187</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>14.624700</td>\n",
       "      <td>88.6650</td>\n",
       "      <td>18.6118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-5697.50</td>\n",
       "      <td>3.3272</td>\n",
       "      <td>8.5459</td>\n",
       "      <td>0.161800</td>\n",
       "      <td>19.838200</td>\n",
       "      <td>25.126200</td>\n",
       "      <td>-0.0116</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>8.5869</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>9.609100</td>\n",
       "      <td>39.7838</td>\n",
       "      <td>11.3379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>-5130.75</td>\n",
       "      <td>3.3744</td>\n",
       "      <td>8.7786</td>\n",
       "      <td>2.420900</td>\n",
       "      <td>17.579100</td>\n",
       "      <td>20.979000</td>\n",
       "      <td>-0.0122</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>8.6381</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>4.298300</td>\n",
       "      <td>25.4882</td>\n",
       "      <td>67.3679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>-5248.75</td>\n",
       "      <td>3.3631</td>\n",
       "      <td>8.7556</td>\n",
       "      <td>-3.090900</td>\n",
       "      <td>23.090900</td>\n",
       "      <td>30.517400</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>7.6805</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>7.245400</td>\n",
       "      <td>81.3239</td>\n",
       "      <td>13.1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>-5415.00</td>\n",
       "      <td>3.4226</td>\n",
       "      <td>9.3960</td>\n",
       "      <td>4.099100</td>\n",
       "      <td>15.900900</td>\n",
       "      <td>18.324800</td>\n",
       "      <td>-0.0132</td>\n",
       "      <td>15.81</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>10.8728</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>3.927300</td>\n",
       "      <td>27.9509</td>\n",
       "      <td>10.4728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>-6504.75</td>\n",
       "      <td>4.6809</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>-2.099100</td>\n",
       "      <td>22.099100</td>\n",
       "      <td>28.287700</td>\n",
       "      <td>-0.0112</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>8.5762</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>4.026200</td>\n",
       "      <td>40.8889</td>\n",
       "      <td>16.9589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-5401.75</td>\n",
       "      <td>3.4199</td>\n",
       "      <td>8.7495</td>\n",
       "      <td>16.790900</td>\n",
       "      <td>23.209100</td>\n",
       "      <td>29.535800</td>\n",
       "      <td>-0.0055</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>6.2614</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>3.577400</td>\n",
       "      <td>78.0045</td>\n",
       "      <td>7.1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>-5686.75</td>\n",
       "      <td>3.4189</td>\n",
       "      <td>8.7897</td>\n",
       "      <td>-1.220900</td>\n",
       "      <td>21.220900</td>\n",
       "      <td>30.056500</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>15.74</td>\n",
       "      <td>0.6887</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>11.5257</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>5.873000</td>\n",
       "      <td>26.2425</td>\n",
       "      <td>6.5821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1175 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature_22  Feature_32  Feature_34  Feature_60  Feature_65  Feature_66  \\\n",
       "160     -5645.25      3.3907      8.3754   14.645500   25.354500   34.515500   \n",
       "814     -6616.00      4.6484      8.6706    5.572236   15.453244   25.628517   \n",
       "124     -5653.75      3.3321      8.7947   29.191800   10.808200   17.468400   \n",
       "501     -5697.50      3.3272      8.5459    0.161800   19.838200   25.126200   \n",
       "1362    -5130.75      3.3744      8.7786    2.420900   17.579100   20.979000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1250    -5248.75      3.3631      8.7556   -3.090900   23.090900   30.517400   \n",
       "365     -5415.00      3.4226      9.3960    4.099100   15.900900   18.324800   \n",
       "1420    -6504.75      4.6809      8.1605   -2.099100   22.099100   28.287700   \n",
       "113     -5401.75      3.4199      8.7495   16.790900   23.209100   29.535800   \n",
       "470     -5686.75      3.4189      8.7897   -1.220900   21.220900   30.056500   \n",
       "\n",
       "      Feature_104  Feature_122  Feature_131  Feature_214  Feature_320  \\\n",
       "160       -0.0056        15.74       0.8300       0.1156      10.0971   \n",
       "814       -0.0106        15.86       0.7402       0.0309       8.6690   \n",
       "124       -0.0050        15.74       0.7429       0.0761      10.8187   \n",
       "501       -0.0116        15.76       0.6645       0.0332       8.5869   \n",
       "1362      -0.0122        15.80       0.7430       0.0657       8.6381   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1250      -0.0053        15.71       0.7304       0.0294       7.6805   \n",
       "365       -0.0132        15.81       0.6469       0.0554      10.8728   \n",
       "1420      -0.0112        15.70       0.7048       0.0729       8.5762   \n",
       "113       -0.0055        15.70       0.6925       0.0763       6.2614   \n",
       "470       -0.0126        15.74       0.6887       0.0648      11.5257   \n",
       "\n",
       "      Feature_352  Feature_478  Feature_511  Feature_578  \n",
       "160        0.0579     6.002000      97.7778      15.0191  \n",
       "814        0.0137     6.178896      50.8235      12.7241  \n",
       "124        0.0355    14.624700      88.6650      18.6118  \n",
       "501        0.0146     9.609100      39.7838      11.3379  \n",
       "1362       0.0275     4.298300      25.4882      67.3679  \n",
       "...           ...          ...          ...          ...  \n",
       "1250       0.0136     7.245400      81.3239      13.1807  \n",
       "365        0.0256     3.927300      27.9509      10.4728  \n",
       "1420       0.0343     4.026200      40.8889      16.9589  \n",
       "113        0.0340     3.577400      78.0045       7.1763  \n",
       "470        0.0268     5.873000      26.2425       6.5821  \n",
       "\n",
       "[1175 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_test = Outlier(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RASHMI~1\\AppData\\Local\\Temp/ipykernel_11820/2160622916.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test_MICE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test_MICE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMICE_imputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_MICE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    663\u001b[0m                     \u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs_corr_mat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                 )\n\u001b[1;32m--> 665\u001b[1;33m                 Xt, estimator = self._impute_one_feature(\n\u001b[0m\u001b[0;32m    666\u001b[0m                     \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m                     \u001b[0mmask_missing_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py\u001b[0m in \u001b[0;36m_impute_one_feature\u001b[1;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_filled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneighbor_feat_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mmissing_row_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_filled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mmissing_row_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# if no missing values, don't predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0mXT_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         \u001b[0meigen_vals_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVD did not converge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         raise ValueError('illegal value in %dth argument of internal gesdd'\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "X_test_MICE = X_test.copy(deep=True)\n",
    "X_test_MICE.iloc[:,:] = pd.DataFrame(MICE_imputer.fit_transform(X_test))\n",
    "X_test = X_test_MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.filter(final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfscore = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "clfscore.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print ('RF accuracy: TRAINING', clfscore.score(X_train,y_train))\n",
    "print ('RF accuracy: TESTING', clfscore.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from scikitplot.metrics import plot_roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", yticklabels = ['Pred. Pass' , 'Pred. Fail'] , \n",
    "            xticklabels = ['Act. Pass', 'Act. Fail'])\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test Accuracy Score\", accuracy_score(y_test, y_pred))\n",
    "metrics.RocCurveDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "g = pca.transform(X_train)\n",
    "g = pd.DataFrame(g, columns=['a','b'])\n",
    "g['Classification'] = y_train\n",
    "sns.scatterplot(data = g , x='a' , y='b', hue = g['Classification'],legend= True )\n",
    "print(pca.explained_variance_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling technique\n",
    "\n",
    "def Sampling(X_train, y_train, sampler):\n",
    "\n",
    "    #SMOTE\n",
    "    if sampler == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=100)    \n",
    "    \n",
    "    #ROSE\n",
    "    if sampler == 'ROSE':\n",
    "        sampler = RandomOverSampler(random_state=100, shrinkage=1)\n",
    "\n",
    "    #ADASYN\n",
    "    if sampler == 'ADASYN':\n",
    "        sampler = ADASYN(random_state=100)\n",
    "    \n",
    "\n",
    "    #SMOTTEENN\n",
    "    if sampler == 'SMOTEENN' :\n",
    "        sampler = SMOTEENN(random_state=100)\n",
    "        \n",
    "        \n",
    "    #Random under Sampling\n",
    "    if sampler == \"randomunder\":\n",
    "        sampler = RandomUnderSampler(random_state=100)\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    counter = Counter(y_resampled)\n",
    "    print(counter)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance treatment\n",
    "from collections import Counter\n",
    "X_resampled, y_resampled = Sampling(X_train, y_train,'SMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_resampled)\n",
    "g = pca.transform(X_resampled)\n",
    "g = pd.DataFrame(g, columns=['a','b'])\n",
    "g['Classification'] = y_resampled\n",
    "sns.scatterplot(data = g , x='a' , y='b', hue= g['Classification'], legend= True )\n",
    "print(pca.explained_variance_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance treatment\n",
    "X_resampled1, y_resampled1 = Sampling(X_train, y_train,'ADASYN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_resampled1)\n",
    "g = pca.transform(X_resampled1)\n",
    "g = pd.DataFrame(g, columns=['a','b'])\n",
    "g['Classification'] = y_resampled1\n",
    "sns.scatterplot(data = g , x='a' , y='b', hue= g['Classification'], legend= True )\n",
    "print(pca.explained_variance_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance treatment\n",
    "X_resampled2, y_resampled2 = Sampling(X_train, y_train,'ROSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_resampled2)\n",
    "g = pca.transform(X_resampled2)\n",
    "g = pd.DataFrame(g, columns=['a','b'])\n",
    "g['Classification'] = y_resampled2\n",
    "sns.scatterplot(data = g , x='a' , y='b', hue= g['Classification'], legend= True )\n",
    "print(pca.explained_variance_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance treatment\n",
    "from imblearn.combine import SMOTEENN\n",
    "X_resampled3, y_resampled3 = Sampling(X_train, y_train,'SMOTEENN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_resampled3)\n",
    "g = pca.transform(X_resampled3)\n",
    "g = pd.DataFrame(g, columns=['a','b'])\n",
    "g['Classification'] = y_resampled3\n",
    "sns.scatterplot(data = g , x='a' , y='b', hue= g['Classification'], legend= True )\n",
    "print(pca.explained_variance_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance treatment\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_resampled4, y_resampled4 = Sampling(X_train, y_train,'randomunder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_resampled4)\n",
    "g = pca.transform(X_resampled4)\n",
    "g = pd.DataFrame(g, columns=['a','b'])\n",
    "g['Classification'] = y_resampled4\n",
    "sns.scatterplot(data = g , x='a' , y='b', hue= g['Classification'], legend= True )\n",
    "print(pca.explained_variance_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))\n",
    "#Percentage of variance explained by each of the selected components"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "base file.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
